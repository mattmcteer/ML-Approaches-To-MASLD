{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings('ignore')\n",
        "import sklearn\n",
        "import sys\n",
        "sys.path\n",
        "sys.path.append('/Users/matthewmcteer/opt/anaconda3/lib/python3.7/site-packages')\n",
        "import shap\n",
        "import xgboost as xgb\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import time\n",
        "import missingno as msno\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1673012253766
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 11 - MASL vs MASH"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 258,
      "metadata": {
        "gather": {
          "logged": 1673019574705
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_11'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_11 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_11'].notna()]\n",
        "\n",
        "df['response_11'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019578567
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 11 extended data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 262,
      "metadata": {
        "gather": {
          "logged": 1673019599161
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 11 extended data)\n",
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1673019603249
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Extended_Response11_METACOHORT.csv')\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_11'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_11 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_11'].notna()]\n",
        "\n",
        "df['response_11'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019606753
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019624463
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 267,
      "metadata": {
        "gather": {
          "logged": 1673019633676
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673008260559
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019642801
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - MASL vs MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673008680554
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 11 imputed data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673008685203
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1673008692073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673008694417
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:38:01] WARNING: /mnt/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n              colsample_bynode=1, colsample_bytree=0.75, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.01, max_delta_step=0.0, max_depth=5,\n              min_child_weight=1.0, missing=nan, monotone_constraints='()',\n              n_estimators=250, n_jobs=-1, num_parallel_tree=1, random_state=42,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1.0, subsample=1,\n              tree_method='auto', validate_parameters=False, verbosity=None)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1673008701519
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - MASL vs. MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673008740465
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1673012276941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 11 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012280073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1673012282326
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1673012284512
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012286508
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012289686
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1673012292739
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012300123
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - Steatosis vs. NASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012438859
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 12 - At-Risk MASH"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read in data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_12'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_12 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_12'].notna()]\n",
        "\n",
        "df['response_12'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 12 data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 12 data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_12'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_12'].notna()]\n",
        "\n",
        "df['response_12'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012441065
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'At-Risk MASH']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012445357
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1673012447443
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012449655
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012453585
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - At-Risk NASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012455960
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 12 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'At-Risk MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012457945
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1673012462986
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012464582
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012466730
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1673012606404
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012610149
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012621633
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - At-Risk NASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012625551
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {
        "gather": {
          "logged": 1673012793123
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('#read imputed extended response 12 data')\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'At-Risk MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012797932
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1673012801151
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1673012804117
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012806661
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012810087
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1673012812855
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673012826697
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "import sklearn.metrics as metrics\n",
        "figure(figsize=(8, 6), dpi=80)\n",
        "from sklearn.metrics import roc_curve\n",
        "from scipy import interp\n",
        "from sklearn.metrics import auc\n",
        "cv = StratifiedKFold(n_splits=10,shuffle=False)\n",
        "\n",
        "#X = X_train_res\n",
        "#y = y_train_res\n",
        "tprs = []\n",
        "aucs = []\n",
        "mean_fpr = np.linspace(0,1,100)\n",
        "i = 1\n",
        "for Train,Test in cv.split(X_train_res,y_train_res):\n",
        "    prediction = model.fit(X_train_res.iloc[Train],y_train_res[Train]).predict_proba(X_train_res.iloc[Test])\n",
        "    fpr, tpr, t = roc_curve(y_train_res[Test], prediction[:, 1])\n",
        "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    aucs.append(roc_auc)\n",
        "    plt.plot(fpr, tpr, lw=2, alpha=0.1, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
        "    i= i+1\n",
        "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
        "         label=r'Mean K-Fold C.V ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for k-Fold Cross-Valdiation (k=10)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "#plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
        "#plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
        "#plt.show() \n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = sklearn.metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('ROC for K-Fold C.V and Test Set')\n",
        "plt.plot(fpr, tpr, 'm', label =r'ROC Test Set (AUC = %0.2f)' % roc_auc, lw = 2, alpha = 1)\n",
        "plt.legend(loc = 'lower right')\n",
        "#plt.plot([0, 1], [0, 1],'k--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - At-Risk NASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013022596
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 13 - High Activity"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_13'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_13 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_13'].notna()]\n",
        "\n",
        "df['response_13'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('#save response 13 extended data')\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('read response 13 extended data')\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_13'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_13 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_13'].notna()]\n",
        "\n",
        "df['response_13'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013025480
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013031284
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 82,
      "metadata": {
        "gather": {
          "logged": 1673013033702
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013036137
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013041611
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013054016
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('#read imputed response 13 extended data')\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013056800
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 89,
      "metadata": {
        "gather": {
          "logged": 1673013063867
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013066369
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013071964
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013111923
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 94,
      "metadata": {
        "gather": {
          "logged": 1673013114798
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('#read imputed response 13 extended data')\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013117305
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 96,
      "metadata": {
        "gather": {
          "logged": 1673013119435
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 97,
      "metadata": {
        "gather": {
          "logged": 1673013121938
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013124442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013126903
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 100,
      "metadata": {
        "gather": {
          "logged": 1673013130195
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:51:49] WARNING: /mnt/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 102,
          "data": {
            "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n              colsample_bynode=1, colsample_bytree=0.75, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0.0, max_depth=12,\n              min_child_weight=1.0, missing=nan, monotone_constraints='()',\n              n_estimators=250, n_jobs=-1, num_parallel_tree=1, random_state=42,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1.0, subsample=1,\n              tree_method='auto', validate_parameters=False, verbosity=None)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 102,
      "metadata": {
        "gather": {
          "logged": 1673013135706
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 84,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013378625
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 14 - Clinically Significant Fibrosis (Histology Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv('# read data')\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_14'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_14 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_14'].notna()]\n",
        "\n",
        "df['response_14'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 14 extended data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 91,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 14 extended data)\n",
        "\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_14'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_14 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_14'].notna()]\n",
        "\n",
        "df['response_14'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013382292
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013388583
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 107,
      "metadata": {
        "gather": {
          "logged": 1673013390982
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013393366
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013399389
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 100,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013411894
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 14 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013415299
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 114,
      "metadata": {
        "gather": {
          "logged": 1673013422786
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013424876
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013430563
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 111,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013567055
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 119,
      "metadata": {
        "gather": {
          "logged": 1673013570144
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 14 extended data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013572859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 121,
      "metadata": {
        "gather": {
          "logged": 1673013575836
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 122,
      "metadata": {
        "gather": {
          "logged": 1673013578124
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013580469
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013583583
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 125,
      "metadata": {
        "gather": {
          "logged": 1673013586185
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013592012
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 125,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013767231
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 15 - Advanced Fibrosis(Histology Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 129,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_15'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_15 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_15'].notna()]\n",
        "\n",
        "df['response_15'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 15 extended data )\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 132,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 15 extended data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_15'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_15 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_15'].notna()]\n",
        "\n",
        "df['response_15'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013778764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013786087
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 132,
      "metadata": {
        "gather": {
          "logged": 1673013790261
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013793704
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673013801845
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 141,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014076497
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 15 imputed extended data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014079956
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 139,
      "metadata": {
        "gather": {
          "logged": 1673014086728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014089114
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014095201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 152,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014192827
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 144,
      "metadata": {
        "gather": {
          "logged": 1673014195142
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read extended imputed data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014198641
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014201008
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 147,
      "metadata": {
        "gather": {
          "logged": 1673014203895
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014206525
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014208889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 150,
      "metadata": {
        "gather": {
          "logged": 1673014212007
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014218049
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 166,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014492862
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 16 - Cirrhosis (Histology Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv('# read data')\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 170,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_16'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_16 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_16'].notna()]\n",
        "\n",
        "df['response_16'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 16 extended data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 173,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 16 extended data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_16'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_16 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_16'].notna()]\n",
        "\n",
        "df['response_16'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014496339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014501734
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 157,
      "metadata": {
        "gather": {
          "logged": 1673014504814
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014507187
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014513141
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 182,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = cross_val_predict(model, X_train, y_train, cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014526157
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 16 imputed data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014529658
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 164,
      "metadata": {
        "gather": {
          "logged": 1673014536837
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014538959
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014544786
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 193,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014616279
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 169,
      "metadata": {
        "gather": {
          "logged": 1673014618938
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 16 imputed data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014622129
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014624485
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 172,
      "metadata": {
        "gather": {
          "logged": 1673014627600
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014629992
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014632363
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 175,
      "metadata": {
        "gather": {
          "logged": 1673014635420
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014641422
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 207,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014892547
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 17 - Advanced Fibrosis (Histology & Clinically Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 211,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_17'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_17 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_17'].notna()]\n",
        "\n",
        "df['response_17'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 17 data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 214,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 17 extended data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_17'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_17 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_17'].notna()]\n",
        "\n",
        "df['response_17'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014895222
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014901296
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 182,
      "metadata": {
        "gather": {
          "logged": 1673014904409
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014906810
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014912831
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 223,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673014998591
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 17)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015001253
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 189,
      "metadata": {
        "gather": {
          "logged": 1673015008137
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015010963
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015016532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 234,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015157131
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 194,
      "metadata": {
        "gather": {
          "logged": 1673015159481
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(# read imputed extended response 17)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015162958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 196,
      "metadata": {
        "gather": {
          "logged": 1673015165731
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 197,
      "metadata": {
        "gather": {
          "logged": 1673015169248
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015171340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015173477
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 200,
      "metadata": {
        "gather": {
          "logged": 1673015176407
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015182187
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 248,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC:  0.961689788847135\n",
            "Accuracy:  0.9007005236134411\n",
            "sensitivity: 0.632398753894081\n",
            "specificity: 0.8974358974358975\n",
            "F1:  0.9020181630076036\n",
            "Test set score: 0.8337\n"
          ]
        }
      ],
      "execution_count": 249,
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015489969
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 18 - Cirrhosis (Histology & Clinically Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 252,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_18'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_18 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_18'].notna()]\n",
        "\n",
        "df['response_18'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('#save response 18 extended data')\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 255,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 18 extended data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_18'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_18 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_18'].notna()]\n",
        "\n",
        "df['response_18'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015492964
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015499501
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 207,
      "metadata": {
        "gather": {
          "logged": 1673015501939
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015504414
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015510681
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 264,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015561520
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 18 extended data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015565189
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 214,
      "metadata": {
        "gather": {
          "logged": 1673015571235
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015574709
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015581219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 275,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015596059
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 219,
      "metadata": {
        "gather": {
          "logged": 1673015598612
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('#read imputed extended response 18 data')\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015603220
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 221,
      "metadata": {
        "gather": {
          "logged": 1673015606436
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 222,
      "metadata": {
        "gather": {
          "logged": 1673015610732
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015613496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015617961
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 225,
      "metadata": {
        "gather": {
          "logged": 1673015621538
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015629891
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 289,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015817684
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 20 - At-Risk MASLD"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv('#read in data')\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 293,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_20'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_20 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_20'].notna()]\n",
        "\n",
        "df['response_20'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 20 data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 296,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 20 data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            #'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    #'single_markers':[\n",
        "            #'LIT_NB_CK18_M30',\n",
        "            #'LIT_NB_CK18_M65',\n",
        "            #'LIT_NB_PRO_C3',\n",
        "            #'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            #'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            #'ADAPT',\n",
        "            #'FIBC3',\n",
        "            #'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_20'\n",
        "    ]\n",
        "}\n",
        "\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "#features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_20 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_20'].notna()]\n",
        "\n",
        "df['response_20'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015822536
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015833721
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 232,
      "metadata": {
        "gather": {
          "logged": 1673015838409
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015844205
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015855400
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 305,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Extended Variables - At-Risk MASLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015860101
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(# read imputed response 20 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015866096
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 239,
      "metadata": {
        "gather": {
          "logged": 1673015877390
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:26]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015882183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015892869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 316,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Extended Variables - At-Risk MASLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015897458
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 244,
      "metadata": {
        "gather": {
          "logged": 1673015902939
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(# read imputed response 20 extended data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea', 'FIB4',\n",
        "              'NFS', 'APRI','BARD','AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015909305
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:26]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015913586
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 247,
      "metadata": {
        "gather": {
          "logged": 1673015918897
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015923902
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015928225
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 250,
      "metadata": {
        "gather": {
          "logged": 1673015934978
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673015945089
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 330,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Extended Variables - At-Risk MASLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673016103029
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}