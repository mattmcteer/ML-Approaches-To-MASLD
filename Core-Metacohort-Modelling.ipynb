{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings('ignore')\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import sys\n",
        "sys.path\n",
        "sys.path.append('/Users/matthewmcteer/opt/anaconda3/lib/python3.7/site-packages')\n",
        "\n",
        "import lightgbm\n",
        "import shap\n",
        "import xgboost as xgb\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import time\n",
        "import missingno as msno\n",
        "\n",
        "import lightgbm as lgbm\n",
        "#import optuna\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1704731757293
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 11 - MASL vs MASH"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_11'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_11 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_11'].notna()]\n",
        "\n",
        "df['response_11'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673444483021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 11 core data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 11 core data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_11'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_11'].notna()]\n",
        "\n",
        "df['response_11'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672834933734
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672834936547
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672834939648
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1672834941906
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672834945952
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672834952212
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1672837108112
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672837114477
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672837121920
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - MASL vs. MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672837518572
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 11 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672837522059
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1672837528943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672837534156
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672837541144
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1672838109581
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672838113453
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672838124614
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - MASL vs. MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672838164429
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1672838169254
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 11 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672838173659
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:19]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1672838177460
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1672838182265
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672838187114
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672838191476
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1672838194767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672838204345
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1672839526891
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672839530513
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672839537015
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - MASL vs. MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672839709671
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 12 - At-Risk MASH"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673444508706
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_12'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_12 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_12'].notna()]\n",
        "\n",
        "df['response_12'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save core response 12 data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read core response 12 data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_12'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_12'].notna()]\n",
        "\n",
        "df['response_12'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672842283865
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672842292380
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'At-Risk MASH']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672842298265
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1672842310188
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672842319174
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672842332809
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1672844402982
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672844412828
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672844429334
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - At-Risk MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672844775802
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 12 imputed core data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'At-Risk MASH']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672844784395
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1672844806494
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672844816397
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672844835762
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 67,
      "metadata": {
        "gather": {
          "logged": 1672845581455
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672845588291
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672845600967
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - At-Risk MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672845703198
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1705062609653
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 12 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Historic Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'At-Risk MASH']\n",
        "df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "(6024, 20)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1705062739315
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:16]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1705062747806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1705062751316
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1705062753290
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1705062755370
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1705062756593
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1704793763602
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1689676154489
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1704793280308
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "import sklearn.metrics as metrics\n",
        "figure(figsize=(8, 6), dpi=80)\n",
        "from sklearn.metrics import roc_curve\n",
        "from scipy import interp\n",
        "from sklearn.metrics import auc\n",
        "cv = StratifiedKFold(n_splits=5,shuffle=False)\n",
        "\n",
        "#X = X_train_res\n",
        "#y = y_train_res\n",
        "tprs = []\n",
        "aucs = []\n",
        "mean_fpr = np.linspace(0,1,100)\n",
        "i = 1\n",
        "for Train,Test in cv.split(X_train_res,y_train_res):\n",
        "    prediction = model.fit(X_train_res.iloc[Train],y_train_res[Train]).predict_proba(X_train_res.iloc[Test])\n",
        "    fpr, tpr, t = roc_curve(y_train_res[Test], prediction[:, 1])\n",
        "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    aucs.append(roc_auc)\n",
        "    plt.plot(fpr, tpr, lw=1, linestyle = 'dotted',alpha=0.1, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
        "    i= i+1\n",
        "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
        "         label=r'Mean K-Fold C.V ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for k-Fold Cross-Valdiation (k=10)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "#plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
        "#plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
        "#plt.show() \n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = sklearn.metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('ROC for K-Fold C.V and Test Set')\n",
        "plt.plot(fpr, tpr, 'm', label =r'ROC Test Set (AUC = %0.2f)' % roc_auc, lw = 2, alpha = 1)\n",
        "plt.legend(loc = 'lower right')\n",
        "#plt.plot([0, 1], [0, 1],'k--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "\n",
        "\n",
        "plt.savefig('/mnt/batch/tasks/shared/LS_root/mounts/clusters/b60224542/code/Users/b6022454/Figure2.eps', format='eps')\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1689691040623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - At-Risk MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1704794075396
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 13 - High Activity"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 126,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_13'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_13'].notna()]\n",
        "\n",
        "df['response_13'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 13 core data)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 129,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 13 core data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_13'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_13'].notna()]\n",
        "\n",
        "df['response_13'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672847616310
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672847623720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672847628763
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1672847634448
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672847639424
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672847650741
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 92,
      "metadata": {
        "gather": {
          "logged": 1672849816367
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672849820604
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672849831163
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672850206569
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 13 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672850210011
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 99,
      "metadata": {
        "gather": {
          "logged": 1672850218108
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672850222651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672850230527
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 103,
      "metadata": {
        "gather": {
          "logged": 1672851433858
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672851437635
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672851445834
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672851635972
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 108,
      "metadata": {
        "gather": {
          "logged": 1672851640661
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 13 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672851645017
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:19]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672851649450
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 111,
      "metadata": {
        "gather": {
          "logged": 1672851652555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672851655584
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672851658735
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 114,
      "metadata": {
        "gather": {
          "logged": 1672851662315
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672851670448
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 117,
      "metadata": {
        "gather": {
          "logged": 1672853014066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853023164
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853037353
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853237401
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 14 - Clinically Significant Fibrosis"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 167,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_14'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_14 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_14'].notna()]\n",
        "\n",
        "df['response_14'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 14 core data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 170,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 14 core data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_14'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_14'].notna()]\n",
        "\n",
        "df['response_14'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853242065
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853247968
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853252782
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 125,
      "metadata": {
        "gather": {
          "logged": 1672853258693
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853262718
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853273903
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 129,
      "metadata": {
        "gather": {
          "logged": 1672853659221
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853666228
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853681661
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672853713188
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 14 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920478496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920482379
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1672920485031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920487553
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1672920491669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920859292
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1672920862701
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 14 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920866051
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:19]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920869970
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1672920873694
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920878240
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920882231
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1672920885777
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672920896195
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921103151
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 15 - Advanced Fibrosis (Histology Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673444593699
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_15'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_15 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_15'].notna()]\n",
        "\n",
        "df['response_15'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 15 data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 211,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 15 data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_15'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_15'].notna()]\n",
        "\n",
        "df['response_15'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921711519
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921716146
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921720898
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1672921724765
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921730345
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673444600855
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921750244
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673444602599
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921779848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921935273
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 15 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921938609
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1672921949770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921955257
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921980606
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672922098295
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1672922102893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 15 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672922106173
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:19]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672922110860
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1672922114416
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672922118460
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672922122530
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1672922126042
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672922134743
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672922335317
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 16 - Cirrhosis (Histology Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#reaed data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673444622255
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_16'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_16'].notna()]\n",
        "\n",
        "df['response_16'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672922341213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 16 core data)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 252,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 16 core data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_16'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_16'].notna()]\n",
        "\n",
        "df['response_16'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923309567
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923318761
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1672923322971
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923326629
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923345278
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923351113
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672921175658
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 16 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923434663
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923439353
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1672923443719
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923447058
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923454164
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923460967
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1672923464897
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 16 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923470049
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:19]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923473625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {
        "gather": {
          "logged": 1672923476894
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923480517
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923483280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1672923487475
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923495941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923639270
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 17 - Advanced Fibrosis (Histology & Clinically Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(# read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 290,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_17'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_17'].notna()]\n",
        "\n",
        "df['response_17'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save core response 17 data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 293,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read core response 17 data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_17'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_17'].notna()]\n",
        "\n",
        "df['response_17'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923643036
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923647066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923654848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "gather": {
          "logged": 1672923658653
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923665126
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923676283
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923780068
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 17 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923784428
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 86,
      "metadata": {
        "gather": {
          "logged": 1672923792011
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923794809
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923808347
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923817019
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 91,
      "metadata": {
        "gather": {
          "logged": 1672923821366
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 17 core imputed data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923825076
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:19]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 93,
      "metadata": {
        "gather": {
          "logged": 1672923829065
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 94,
      "metadata": {
        "gather": {
          "logged": 1672923833362
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923838493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923842405
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 97,
      "metadata": {
        "gather": {
          "logged": 1672923846482
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672923855122
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672924131707
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 18 - Cirrhosis (Histology & Clinically Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 154,
      "metadata": {
        "gather": {
          "logged": 1673005761822
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_18'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_18 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_18'].notna()]\n",
        "\n",
        "df['response_18'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673005766049
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673005770642
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 18 core data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 157,
      "metadata": {
        "gather": {
          "logged": 1673005781906
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 18 core data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_18'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_18'].notna()]\n",
        "\n",
        "df['response_18'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673005803451
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673005806728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673005809993
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 162,
      "metadata": {
        "gather": {
          "logged": 1673005812362
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673005817039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673005835935
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673005910111
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 18 core data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929250319
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 105,
      "metadata": {
        "gather": {
          "logged": 1672929271136
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929290658
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929324895
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929342699
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 110,
      "metadata": {
        "gather": {
          "logged": 1672929350392
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read core imputed response 18 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929363161
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:19]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 112,
      "metadata": {
        "gather": {
          "logged": 1672929368603
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 113,
      "metadata": {
        "gather": {
          "logged": 1672929375353
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929384645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929392213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 116,
      "metadata": {
        "gather": {
          "logged": 1672929398239
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929420836
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929693374
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 20 - At-Risk MASLD"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 372,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_20'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_20'].notna()]\n",
        "\n",
        "df['response_20'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save core response 20 data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 375,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read core response 20 data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',                     \n",
        "            'dyslipidaemia',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
        "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
        "            'AST_ALT_Ratio',                    \n",
        "                             ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_20'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_7 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_20'].notna()]\n",
        "\n",
        "df['response_20'].value_counts()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929699856
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929705788
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929712807
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 123,
      "metadata": {
        "gather": {
          "logged": 1672929719139
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929725175
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672929735982
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 127,
      "metadata": {
        "gather": {
          "logged": 1672930309038
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930316839
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Core Variables - At-Risk NAFLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930447895
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed core response 20 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930454632
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930462692
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 132,
      "metadata": {
        "gather": {
          "logged": 1672930468609
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:19]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930472713
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930482126
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = cross_val_predict(model, X_train, y_train, cv=kfold)\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Core Variables - At-Risk NAFLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930487069
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 137,
      "metadata": {
        "gather": {
          "logged": 1672930490204
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read core imputed response 20 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930502542
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:19]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930505280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 140,
      "metadata": {
        "gather": {
          "logged": 1672930507880
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930512515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930515446
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 143,
      "metadata": {
        "gather": {
          "logged": 1672930519617
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930527409
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res , plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Core Variables - At-Risk NAFLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1672930740921
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}