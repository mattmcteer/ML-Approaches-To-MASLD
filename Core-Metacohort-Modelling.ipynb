{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append('/Users/matthewmcteer/opt/anaconda3/lib/python3.7/site-packages')\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import time\n",
    "import missingno as msno\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 11 - MASL vs MASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload Dataset\n",
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#Data)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_11'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where MASL vs MASH = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_11'].notna()]\n",
    "\n",
    "df['response_11'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart displaying level of completeness for each feature\n",
    "null_values_bar = msno.bar(df,labels=True)\n",
    "null_values_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Baseline, Metacohort Dataset\n",
    "df.to_csv(#Saved data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#Upload saved data)\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_11'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_11'].notna()]\n",
    "\n",
    "df['response_11'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'MASL vs. MASH']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['MASL vs. NASH']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - MASL vs MASH\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#Upload imputed dataset)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'MASL vs. MASH']\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['MASL vs. MASH']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    ")\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - MASL vs. NASH\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Core_Response11_METACOHORT_MICE.csv')\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'MASL vs MASH]\n",
    "df.shape\n",
    "\n",
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['MASL vs. NASH']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = cross_val_predict(model, X_train_res, y_train_res, cv=kfold)\n",
    "tn, fp, fn, tp = confusion_matrix(y_train_res, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - MASL vs. MASH\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 12 - At-Risk MASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#Read in dataset)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_12'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_12 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_12'].notna()]\n",
    "\n",
    "df['response_12'].value_counts()\n",
    "\n",
    "#Save data\n",
    "df.to_csv(#Save data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#data)\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_7'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_12 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_12'].notna()]\n",
    "\n",
    "df['response_12'].value_counts()\n",
    "\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'At-Risk MASH']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['At-Risk MASH']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - At-Risk MASH\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'At-Risk MASH']\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['At-Risk MASH']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - At-Risk MASH\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Historic Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'At-Risk MASH']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['At-Risk MASH']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - At-Risk MASH\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 13 - High Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#read in data)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_13'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_13'].notna()]\n",
    "\n",
    "df['response_13'].value_counts()\n",
    "\n",
    "df.to_csv(#save data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read data)\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_13'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_13 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_13'].notna()]\n",
    "\n",
    "df['response_13'].value_counts()\n",
    "\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'High Activity']\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['High Activity']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - High Activity\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'High Activity']\n",
    "df.shape\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['High Activity']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - High Activity\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'High Activity']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['High Activity']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - High Activity\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 14 - Clinically Significant Fibrosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#read data)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_14'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_14'].notna()]\n",
    "\n",
    "df['response_14'].value_counts()\n",
    "\n",
    "df.to_csv(#save data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Core_Response14_METACOHORT.csv')\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_14'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_14 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_14'].notna()]\n",
    "\n",
    "df['response_14'].value_counts()\n",
    "\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Clinically Significant Fibrosis']\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Clinically Significant Fibrosis']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - Clinically Significant Fibrosis\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed dataset)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Clinically Significant Fibrosis']\n",
    "df.shape\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Clinically Significant Fibrosis']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - Clinically Significant Fibrosis\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed dataset)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Clinically Significant Fibrosis']\n",
    "df.shape\n",
    "\n",
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['Clinically Significant Fibrosis']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - Clinically Significant Fibrosis\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 15  - Advanced Fibrosis (Histology Confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#read dataset)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_15'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_15'].notna()]\n",
    "\n",
    "df['response_15'].value_counts()\n",
    "\n",
    "df.to_csv(#save data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read data)\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_15'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_15'].notna()]\n",
    "\n",
    "df['response_15'].value_counts()\n",
    "\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Advanced Fibrosis (Histology Confirmed)']\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Advanced Fibrosis (Histology Confirmed)']\n",
    "df.shape\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Advanced Fibrosis (Histology Confirmed)']\n",
    "df.shape\n",
    "\n",
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 16 - Cirrhosis (Histology Confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#read data)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_16'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_16'].notna()]\n",
    "\n",
    "df['response_16'].value_counts()\n",
    "df.to_csv(#save data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read data)\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_16'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_16 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_16'].notna()]\n",
    "\n",
    "df['response_16'].value_counts()\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Cirrhosis (Histology Confirmed)']\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Cirrhosis (Histology Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - Cirrhosis (Histology Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(# read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Cirrhosis (Histology Confirmed)']\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Cirrhosis (Histology Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - Cirrhosis (Histology Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Cirrhosis (Histology Confirmed)']\n",
    "df.shape\n",
    "\n",
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['Cirrhosis (Histology Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - Cirrhosis (Histology Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 17 - Advanced Fibrosis (Histology & Clinically Confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#read data)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_17'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_17'].notna()]\n",
    "\n",
    "df['response_17'].value_counts()\n",
    "\n",
    "df.to_csv(#save data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Core_Response17_METACOHORT.csv')\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_17'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_17 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_17'].notna()]\n",
    "\n",
    "df['response_17'].value_counts()\n",
    "\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Advanced Fibrosis (Histology & Clinical)']\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Advanced Fibrosis (Histology & Clinical)']\n",
    "df.shape\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(# read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Advanced Fibrosis (Histology & Clinical)']\n",
    "df.shape\n",
    "\n",
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 18 - Cirrhosis (Histology & Clinically Confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#read data)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_18'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_18 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_18'].notna()]\n",
    "\n",
    "df['response_18'].value_counts()\n",
    "df.to_csv(#save data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Core_Response18_METACOHORT.csv')\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_18'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_18 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_18'].notna()]\n",
    "\n",
    "df['response_18'].value_counts()\n",
    "\n",
    "\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
    "              colsample_bynode=None, colsample_bytree=0.75, gamma=None,\n",
    "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
    "              learning_rate=0.1, max_delta_step=0.0, max_depth=5,\n",
    "              min_child_weight=1.0, monotone_constraints=None,\n",
    "              n_estimators=250, n_jobs=-1, num_parallel_tree=None,\n",
    "              random_state=42, reg_alpha=None, reg_lambda=None,\n",
    "              scale_pos_weight=1.0, subsample=None, tree_method='auto',\n",
    "              validate_parameters=False, verbosity=None)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed dataset)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
    "df.shape\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
    "df.shape\n",
    "\n",
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response 20 - At-Risk MASLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only considering Baseline Event Types\n",
    "df = pd.read_csv(#read data)\n",
    "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
    "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_20'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_20'].notna()]\n",
    "\n",
    "df['response_20'].value_counts()\n",
    "\n",
    "df.to_csv(#save data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read data)\n",
    "\n",
    "features_list = {\n",
    "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
    "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
    "           'CPH_EV_CI_BMI_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
    "            'insulin_resistance',\n",
    "            'hypertensive',\n",
    "            'idf_metabolic_syndrome',\n",
    "            'eGFR',                     \n",
    "            'dyslipidaemia',\n",
    "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
    "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
    "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',      \n",
    "            'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
    "            'TBL.ALL.EVENTS..AE_CD_OSA',\n",
    "            'AST_ALT_Ratio',                    \n",
    "                             ],\n",
    "    \n",
    "    'target':[\n",
    "        'response_20'\n",
    "    ]\n",
    "}\n",
    "features = []\n",
    "features = features + features_list['std_clinical_features']\n",
    "features = features + features_list['target']\n",
    "\n",
    "#Remove all rows where response_7 = NaN\n",
    "df = df[features]\n",
    "df = df[df['response_20'].notna()]\n",
    "\n",
    "df['response_20'].value_counts()\n",
    "\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'response_20']\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['response_20']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB - Core Variables - At-Risk MASLD\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(# read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'response_20']\n",
    "df.shape\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "#Create train and test sets  \n",
    "X = df.iloc[:,:19]\n",
    "y = df['response_20']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE - Core Variables - At-Risk MASLD\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + MICE + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#read imputed data)\n",
    "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
    "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'ALT', 'AST', 'GGT', 'Platelets', 'Creatinine',\n",
    "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'Obstructive Sleep Apnoea', 'AST-ALT Ratio',\n",
    "              'response_20']\n",
    "df.shape\n",
    "\n",
    "#Create train and test sets\n",
    "X = df.iloc[:,:19]\n",
    "y = df['response_20']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "#Specify XGBoost Classifiers static parameters\n",
    "XGBCL_STATIC_PARAMS = {\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'max_delta_step': 0.0,\n",
    "    'min_child_weight': 1.0,\n",
    "    'missing': None,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'random_state': 42,\n",
    "    'scale_pos_weight': 1.0,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "#Specify number of k-fold cross validation\n",
    "KFOLD_STATIC_PARAMS = {\n",
    "    'n_splits': 5,  # At least 2\n",
    "    'shuffle': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "#Specify grid search static parameters\n",
    "SEARCH_GRID_STATIC_PARAMS = {\n",
    "    'n_jobs': -1, \n",
    "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Grid search XGBoost parameters with following values / ranges\n",
    "SEARCH_GRID_PARAMS = { \n",
    "    'colsample_bytree':[.75, .8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    #'gamma': [0.0, 1.0],\n",
    "    'max_depth':[1,2,5,8,12],\n",
    "    'n_estimators': list(range(50, 300, 50)),\n",
    "    #'num_parallel_tree': [1, 2, 4, 8],\n",
    "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
    "    #'subsample':[.75,1],\n",
    "}\n",
    "\n",
    "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
    "\n",
    "xgbcl = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
    ")\n",
    "\n",
    "#Specify k-fold cross-validation\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
    "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
    "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
    ")\n",
    "\n",
    "#Define grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgbcl,\n",
    "    param_grid = SEARCH_GRID_PARAMS, \n",
    "    cv = kfold,\n",
    "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
    "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
    ")\n",
    "\n",
    "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
    "start_time = time.time()\n",
    "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f'Training performed in {grid_search_time/60} minutes')\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')\n",
    "\n",
    "#Print XGBoost model that gave best accuracy score from grid search\n",
    "model = xgb.XGBClassifier(\n",
    "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
    "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
    "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
    "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
    "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
    "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
    "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
    "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
    "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
    "    \n",
    "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
    "    learning_rate = grid_result.best_params_['learning_rate'], \n",
    "    #gamma = grid_result.best_params_['gamma'],\n",
    "    max_depth = grid_result.best_params_['max_depth'], \n",
    "    n_estimators = grid_result.best_params_['n_estimators'],\n",
    "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
    "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
    "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
    "    #subsample = grid_result.best_params_['subsample'],\n",
    "\n",
    ")\n",
    "print(model)\n",
    "#Fit the model onto X_train and y_train data\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "#refit the model on k-folds to get stable avg error metrics\n",
    "scores = cross_validate(\n",
    "    estimator = model, \n",
    "    X = X_train_res, \n",
    "    y = y_train_res, \n",
    "    cv = kfold, \n",
    "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
    "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "#Print metrics to evaluate model. \n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print('AUC: ',       scores['test_roc_auc'].mean())\n",
    "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
    "print('sensitivity:', sens)\n",
    "print('specificity:', spec)\n",
    "print('F1: ',        scores['test_f1'].mean())\n",
    "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "#Add SHAP values\n",
    "\n",
    "explainer = shap.TreeExplainer(\n",
    "    model, \n",
    "    model_output='probability', \n",
    "    feature_dependence='interventional', \n",
    "    data=X_train_res\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_res)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "shap_values\n",
    "\n",
    "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
    "shap.summary_plot(shap_values, X_train_res , plot_type=\"bar\",show=False)\n",
    "plt.title(\"XGB + MICE + SMOTE - Core Variables - At-Risk MASLD\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
