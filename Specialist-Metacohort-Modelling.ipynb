{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings('ignore')\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import sys\n",
        "sys.path\n",
        "sys.path.append('/Users/matthewmcteer/opt/anaconda3/lib/python3.7/site-packages')\n",
        "\n",
        "import lightgbm\n",
        "import shap\n",
        "import xgboost as xgb\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import time\n",
        "import missingno as msno\n",
        "\n",
        "import lightgbm as lgbm\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1673017641884
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 11 - MASL vs MASH"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_11'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_11 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_11'].notna()]\n",
        "\n",
        "df['response_11'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#specialist cohort index numbers\n",
        "\n",
        "response11_idx = [156, 218, 224, 230, 231, 235, 251, 256, 258, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1162, 1185, 1219, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1385, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2098, 2101, 2105, 4126, 4202, 4205, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4544, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4556, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4571, 4574, 4575, 4577, 4579, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4626, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4656, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5227, 5229, 5230, 5235, 5243, 5256, 5259, 5273, 5275, 5281, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5504, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5530, 5533, 5535, 5537, 5539, 5545, 5550, 5554, 5555, 5556, 5562, 5563, 5566, 5571, 5574, 5580, 5585, 5586, 5587, 5589, 5594, 5595, 5600, 5602, 5608, 5610, 5618, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5643, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5827, 5830, 5836, 5840, 5845, 5852, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5930, 5934, 5939, 5944, 5964, 5970, 5972, 5981, 5986, 5997, 5998, 6006, 6015, 6016, 6018, 6022, 6031, 6033, 6035, 6037, 6045, 6047, 6053, 6054, 6056, 6060, 6067, 6072, 6079, 6087, 6093, 6099, 6108, 6119, 6126, 6134, 6158, 6162, 6168, 6179, 6200, 6204, 6227, 6236, 6237, 6250, 6262, 6297, 6299, 6307, 6317, 6320, 6327, 6328, 6329, 6331, 6348, 6353, 6354, 6365, 6367, 6368, 6373, 6374, 6390, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6437, 6440, 6449, 6463, 6465, 6469, 6503, 6507, 6513, 6521, 6532, 6537, 6545, 6550, 6555, 6562, 6572, 6587, 6593, 6629, 6635, 6664, 6669, 6674, 6681, 6693, 6703, 6713, 6718, 6723, 6726, 6736, 6771, 6777, 6789, 6792, 6803, 6830, 6835, 6858, 6862, 6871, 6885, 6889, 6893, 6896, 6909, 6914, 6921, 6929, 6942, 6953, 6959, 6984, 6987, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7193, 7197, 7204, 7208, 7210, 7211, 7225, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8438, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8496, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8583, 8584, 8585, 8588, 8590, 8592, 8595, 8597, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8616, 8618, 8619, 8622, 8625, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8696, 8700, 8701, 8706, 8708, 8709, 8711, 8713, 8717, 8722, 8724, 8725, 8728, 8729, 8730, 8733, 8736, 8737, 8741, 8742, 8745, 8747, 8750, 9084, 9085, 9086, 9087, 9088, 9090, 9091, 9102, 9103, 9104, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9156]"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[response11_idx]\n",
        "df = df[df['response_11'].notna()]\n",
        "df['response_11'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 11 specialist data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 11 specialist data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_11'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_11 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_11'].notna()]\n",
        "\n",
        "df['response_11'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017650256
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017655377
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1673017657266
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017658748
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017668271
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - MASL vs. MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017674764
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 11 specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017691810
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1673017698183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017699669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017708817
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - MASL vs. MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017715639
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1673017717726
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 11 specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'MASL vs. MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017720602
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['MASL vs. MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1673017723290
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1673017725188
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017726921
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017730190
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1673017733235
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017737553
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - MASL vs. MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017753296
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 12 - At-Risk MASH"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_7'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_12 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_12'].notna()]\n",
        "\n",
        "df['response_12'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Specialist cohort index numbers\n",
        "response12_idx = [156, 218, 224, 230, 231, 235, 251, 256, 258, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1162, 1185, 1219, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1385, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2098, 2101, 2105, 4126, 4202, 4205, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4544, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4556, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4571, 4574, 4575, 4577, 4579, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4626, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4656, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5227, 5229, 5230, 5235, 5243, 5256, 5259, 5273, 5275, 5281, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5504, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5530, 5533, 5535, 5537, 5539, 5541, 5545, 5550, 5554, 5555, 5556, 5562, 5563, 5566, 5571, 5574, 5580, 5585, 5586, 5587, 5589, 5594, 5595, 5600, 5602, 5608, 5610, 5618, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5643, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5821, 5827, 5830, 5836, 5840, 5845, 5852, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5930, 5934, 5939, 5944, 5964, 5970, 5972, 5981, 5986, 5997, 5998, 6006, 6015, 6016, 6018, 6022, 6031, 6033, 6035, 6037, 6045, 6047, 6053, 6054, 6056, 6060, 6067, 6072, 6076, 6079, 6087, 6093, 6099, 6108, 6119, 6126, 6134, 6158, 6162, 6168, 6179, 6200, 6204, 6227, 6236, 6237, 6250, 6262, 6297, 6299, 6307, 6315, 6317, 6320, 6327, 6328, 6329, 6331, 6348, 6353, 6354, 6365, 6367, 6368, 6373, 6374, 6390, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6437, 6440, 6449, 6463, 6465, 6469, 6503, 6507, 6513, 6521, 6532, 6537, 6545, 6550, 6555, 6562, 6572, 6587, 6593, 6629, 6635, 6664, 6669, 6674, 6681, 6693, 6703, 6713, 6718, 6723, 6726, 6736, 6771, 6777, 6789, 6792, 6803, 6830, 6835, 6858, 6862, 6871, 6885, 6889, 6893, 6896, 6909, 6914, 6921, 6929, 6942, 6953, 6959, 6984, 6987, 7001, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7193, 7197, 7204, 7208, 7210, 7211, 7225, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8438, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8496, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8583, 8584, 8585, 8588, 8590, 8592, 8595, 8597, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8616, 8618, 8619, 8622, 8625, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8696, 8700, 8701, 8706, 8708, 8709, 8711, 8713, 8715, 8717, 8722, 8724, 8725, 8728, 8729, 8730, 8733, 8736, 8737, 8741, 8742, 8745, 8747, 8750, 9084, 9085, 9086, 9087, 9088, 9090, 9091, 9102, 9103, 9104, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9156]"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[response12_idx]\n",
        "df = df[df['response_7'].notna()]\n",
        "df['response_7'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 12 specialist data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read specialist response 12 data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_12'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_12 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_12'].notna()]\n",
        "\n",
        "df['response_12'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017769224
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1673017778202
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017780492
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017788574
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 150,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - At-Risk MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017799785
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read specialist response 12 imputed data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'At-Risk MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017801942
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017808283
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1673017810896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017812660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017817680
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 161,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - At-Risk MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017823010
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1673017825245
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed response 12 specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'At-Risk MASH']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017827879
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['At-Risk MASH']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1673017830144
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1673017831956
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017834885
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017837746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1673017839557
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017844062
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 175,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "import sklearn.metrics as metrics\n",
        "figure(figsize=(8, 6), dpi=80)\n",
        "from sklearn.metrics import roc_curve\n",
        "from scipy import interp\n",
        "from sklearn.metrics import auc\n",
        "cv = StratifiedKFold(n_splits=10,shuffle=False)\n",
        "\n",
        "#X = X_train_res\n",
        "#y = y_train_res\n",
        "tprs = []\n",
        "aucs = []\n",
        "mean_fpr = np.linspace(0,1,100)\n",
        "i = 1\n",
        "for Train,Test in cv.split(X_train_res,y_train_res):\n",
        "    prediction = model.fit(X_train_res.iloc[Train],y_train_res[Train]).predict_proba(X_train_res.iloc[Test])\n",
        "    fpr, tpr, t = roc_curve(y_train_res[Test], prediction[:, 1])\n",
        "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    aucs.append(roc_auc)\n",
        "    plt.plot(fpr, tpr, lw=2, alpha=0.1, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
        "    i= i+1\n",
        "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
        "         label=r'Mean K-Fold C.V ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for k-Fold Cross-Valdiation (k=10)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "#plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
        "#plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
        "#plt.show() \n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = sklearn.metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('ROC for K-Fold C.V and Test Set')\n",
        "plt.plot(fpr, tpr, 'm', label =r'ROC Test Set (AUC = %0.2f)' % roc_auc, lw = 2, alpha = 1)\n",
        "plt.legend(loc = 'lower right')\n",
        "#plt.plot([0, 1], [0, 1],'k--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - At-Risk MASH\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017854758
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 13 - High Activity"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 181,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_13'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_13 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_13'].notna()]\n",
        "\n",
        "df['response_13'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#specialist cohort index numbers\n",
        "\n",
        "response13_idx = [156, 218, 224, 230, 231, 235, 251, 256, 258, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1162, 1185, 1219, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1385, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2098, 2101, 2105, 4126, 4202, 4205, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4544, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4556, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4571, 4574, 4575, 4577, 4579, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4626, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4656, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5227, 5229, 5230, 5235, 5243, 5256, 5259, 5273, 5275, 5281, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5504, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5530, 5533, 5535, 5537, 5539, 5545, 5550, 5554, 5555, 5556, 5562, 5563, 5566, 5571, 5574, 5580, 5585, 5586, 5587, 5589, 5594, 5595, 5600, 5602, 5608, 5610, 5618, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5643, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5827, 5830, 5836, 5840, 5845, 5852, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5930, 5934, 5939, 5944, 5964, 5970, 5972, 5981, 5986, 5997, 5998, 6006, 6015, 6016, 6018, 6022, 6031, 6033, 6035, 6037, 6045, 6047, 6053, 6054, 6056, 6060, 6067, 6072, 6079, 6087, 6093, 6099, 6108, 6119, 6126, 6134, 6158, 6162, 6168, 6179, 6200, 6204, 6227, 6236, 6237, 6250, 6262, 6297, 6299, 6307, 6317, 6320, 6327, 6328, 6329, 6331, 6348, 6353, 6354, 6365, 6367, 6368, 6373, 6374, 6390, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6437, 6440, 6449, 6463, 6465, 6469, 6503, 6507, 6513, 6521, 6532, 6537, 6545, 6550, 6555, 6562, 6572, 6587, 6593, 6629, 6635, 6664, 6669, 6674, 6681, 6693, 6703, 6713, 6718, 6723, 6726, 6736, 6771, 6777, 6789, 6792, 6803, 6830, 6835, 6858, 6862, 6871, 6885, 6889, 6893, 6896, 6909, 6914, 6921, 6929, 6942, 6953, 6959, 6984, 6987, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7193, 7197, 7204, 7208, 7210, 7211, 7225, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8438, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8496, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8583, 8584, 8585, 8588, 8590, 8592, 8595, 8597, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8616, 8618, 8619, 8622, 8625, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8696, 8700, 8701, 8706, 8708, 8709, 8711, 8713, 8717, 8722, 8724, 8725, 8728, 8729, 8730, 8733, 8736, 8737, 8741, 8742, 8745, 8747, 8750, 9084, 9085, 9086, 9087, 9088, 9090, 9091, 9102, 9103, 9104, 9105, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9154, 9155, 9156]"
      ],
      "outputs": [],
      "execution_count": 183,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[response13_idx]\n",
        "df = df[df['response_13'].notna()]\n",
        "df['response_13'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('#save specialist response 13 data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 187,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read specialist response 13 data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_13'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_13 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_13'].notna()]\n",
        "\n",
        "df['response_13'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017861867
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017864532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017867331
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1673017869244
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017871515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017881193
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 196,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017889898
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed specialist response 13 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017892926
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1673017899377
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017901676
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017913566
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 207,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017922038
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 68,
      "metadata": {
        "gather": {
          "logged": 1673017924005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed specialist response 13 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'High Activity']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017927031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['High Activity']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {
        "gather": {
          "logged": 1673017929782
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1673017933066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017935309
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017937551
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1673017939169
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017949275
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 221,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - High Activity\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017964519
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 14 - Clinically Significant Fibrosis "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 225,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_14'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_14 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_14'].notna()]\n",
        "\n",
        "df['response_14'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#response 14 specialist indexes\n",
        "response14_idx = [156, 218, 224, 230, 231, 235, 251, 256, 258, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1162, 1185, 1219, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1385, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2098, 2101, 2105, 4126, 4202, 4205, 4441, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4544, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4556, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4571, 4574, 4575, 4577, 4579, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4626, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4656, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5227, 5229, 5230, 5235, 5243, 5256, 5259, 5273, 5275, 5281, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5504, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5530, 5533, 5535, 5537, 5539, 5545, 5550, 5554, 5555, 5556, 5562, 5563, 5566, 5571, 5574, 5580, 5585, 5586, 5587, 5589, 5594, 5595, 5600, 5602, 5608, 5610, 5618, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5643, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5821, 5827, 5830, 5836, 5840, 5845, 5852, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5930, 5934, 5939, 5944, 5964, 5970, 5972, 5981, 5986, 5997, 5998, 6006, 6015, 6016, 6018, 6022, 6031, 6033, 6035, 6037, 6045, 6047, 6053, 6054, 6056, 6060, 6067, 6072, 6076, 6079, 6087, 6093, 6099, 6108, 6119, 6126, 6134, 6158, 6162, 6168, 6179, 6200, 6204, 6227, 6236, 6237, 6250, 6262, 6297, 6299, 6307, 6317, 6320, 6327, 6328, 6329, 6331, 6348, 6353, 6354, 6365, 6367, 6368, 6373, 6374, 6390, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6437, 6440, 6449, 6463, 6465, 6469, 6503, 6507, 6513, 6521, 6532, 6537, 6545, 6550, 6555, 6562, 6572, 6587, 6593, 6629, 6635, 6664, 6669, 6674, 6681, 6693, 6703, 6713, 6718, 6723, 6726, 6736, 6771, 6777, 6789, 6792, 6803, 6830, 6835, 6858, 6862, 6871, 6885, 6889, 6893, 6896, 6909, 6914, 6921, 6929, 6942, 6953, 6959, 6984, 6987, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7193, 7197, 7204, 7208, 7210, 7211, 7225, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8438, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8496, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8583, 8584, 8585, 8588, 8590, 8592, 8595, 8597, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8616, 8618, 8619, 8622, 8625, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8696, 8700, 8701, 8706, 8708, 8709, 8711, 8713, 8717, 8722, 8724, 8725, 8728, 8729, 8730, 8733, 8736, 8737, 8741, 8742, 8745, 8747, 8750, 9084, 9085, 9086, 9087, 9088, 9090, 9091, 9102, 9103, 9104, 9105, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9154, 9155, 9156]"
      ],
      "outputs": [],
      "execution_count": 227,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[response14_idx]\n",
        "df = df[df['response_14'].notna()]\n",
        "df['response_14'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 14 specialist data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 231,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 14 specialist data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_14'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_14 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_14'].notna()]\n",
        "\n",
        "df['response_14'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017968316
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017970286
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017972497
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 81,
      "metadata": {
        "gather": {
          "logged": 1673017974203
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017976365
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017987285
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 240,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017993638
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 14 imputed specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673017999360
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1673018006846
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018009920
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018020603
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 251,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018031973
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 93,
      "metadata": {
        "gather": {
          "logged": 1673018034628
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 14 imputed specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Clinically Significant Fibrosis']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018037156
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['Clinically Significant Fibrosis']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018039225
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 96,
      "metadata": {
        "gather": {
          "logged": 1673018041324
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018044273
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018046755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 99,
      "metadata": {
        "gather": {
          "logged": 1673018048632
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018059648
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 265,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - Clinically Significant Fibrosis\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018075184
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 15 - Advanced Fibrosis (Histology Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 269,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_15'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_15 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_15'].notna()]\n",
        "\n",
        "df['response_15'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#response 15 specialist index\n",
        "\n",
        "response15_idx = [156, 218, 224, 230, 231, 235, 251, 256, 258, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1162, 1185, 1219, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1385, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2098, 2101, 2105, 4126, 4202, 4205, 4441, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4544, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4556, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4571, 4574, 4575, 4577, 4579, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4626, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4656, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5227, 5229, 5230, 5235, 5243, 5256, 5259, 5273, 5275, 5281, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5504, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5530, 5533, 5535, 5537, 5539, 5545, 5550, 5554, 5555, 5556, 5562, 5563, 5566, 5571, 5574, 5580, 5585, 5586, 5587, 5589, 5594, 5595, 5600, 5602, 5608, 5610, 5618, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5643, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5821, 5827, 5830, 5836, 5840, 5845, 5852, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5930, 5934, 5939, 5944, 5964, 5970, 5972, 5981, 5986, 5997, 5998, 6006, 6015, 6016, 6018, 6022, 6031, 6033, 6035, 6037, 6045, 6047, 6053, 6054, 6056, 6060, 6067, 6072, 6076, 6079, 6087, 6093, 6099, 6108, 6119, 6126, 6134, 6158, 6162, 6168, 6179, 6200, 6204, 6227, 6236, 6237, 6250, 6262, 6297, 6299, 6307, 6317, 6320, 6327, 6328, 6329, 6331, 6348, 6353, 6354, 6365, 6367, 6368, 6373, 6374, 6390, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6437, 6440, 6449, 6463, 6465, 6469, 6503, 6507, 6513, 6521, 6532, 6537, 6545, 6550, 6555, 6562, 6572, 6587, 6593, 6629, 6635, 6664, 6669, 6674, 6681, 6693, 6703, 6713, 6718, 6723, 6726, 6736, 6771, 6777, 6789, 6792, 6803, 6830, 6835, 6858, 6862, 6871, 6885, 6889, 6893, 6896, 6909, 6914, 6921, 6929, 6942, 6953, 6959, 6984, 6987, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7193, 7197, 7204, 7208, 7210, 7211, 7225, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8438, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8496, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8583, 8584, 8585, 8588, 8590, 8592, 8595, 8597, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8616, 8618, 8619, 8622, 8625, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8696, 8700, 8701, 8706, 8708, 8709, 8711, 8713, 8717, 8722, 8724, 8725, 8728, 8729, 8730, 8733, 8736, 8737, 8741, 8742, 8745, 8747, 8750, 9084, 9085, 9086, 9087, 9088, 9090, 9091, 9102, 9103, 9104, 9105, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9154, 9155, 9156]"
      ],
      "outputs": [],
      "execution_count": 271,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[response15_idx]\n",
        "df = df[df['response_15'].notna()]\n",
        "df['response_15'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 15 specialist data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 275,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 15 specialist data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_15'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_15 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_15'].notna()]\n",
        "\n",
        "df['response_15'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018078935
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018084411
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 106,
      "metadata": {
        "gather": {
          "logged": 1673018086623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018088626
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018099056
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 284,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018107302
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed specialist response 15 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018111234
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 113,
      "metadata": {
        "gather": {
          "logged": 1673018117829
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018119924
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018128635
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 295,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018139815
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 118,
      "metadata": {
        "gather": {
          "logged": 1673018141973
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed specialist response 15 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology Confirmed)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018145455
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['Advanced Fibrosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 120,
      "metadata": {
        "gather": {
          "logged": 1673018148300
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 121,
      "metadata": {
        "gather": {
          "logged": 1673018150468
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018153128
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018155513
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 124,
      "metadata": {
        "gather": {
          "logged": 1673018157359
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018200949
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 309,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - Advanced Fibrosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018213077
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 16 - Cirrhosis (Histology Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 313,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_16'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_16 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_16'].notna()]\n",
        "\n",
        "df['response_16'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#response 16 specialist indexes\n",
        "response16_idx = [156, 218, 224, 230, 231, 235, 251, 256, 258, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1162, 1185, 1219, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1385, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2098, 2101, 2105, 4126, 4202, 4205, 4441, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4544, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4556, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4571, 4574, 4575, 4577, 4579, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4626, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4656, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5227, 5229, 5230, 5235, 5243, 5256, 5259, 5273, 5275, 5281, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5504, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5530, 5533, 5535, 5537, 5539, 5545, 5550, 5554, 5555, 5556, 5562, 5563, 5566, 5571, 5574, 5580, 5585, 5586, 5587, 5589, 5594, 5595, 5600, 5602, 5608, 5610, 5618, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5643, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5821, 5827, 5830, 5836, 5840, 5845, 5852, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5930, 5934, 5939, 5944, 5964, 5970, 5972, 5981, 5986, 5997, 5998, 6006, 6015, 6016, 6018, 6022, 6031, 6033, 6035, 6037, 6045, 6047, 6053, 6054, 6056, 6060, 6067, 6072, 6076, 6079, 6087, 6093, 6099, 6108, 6119, 6126, 6134, 6158, 6162, 6168, 6179, 6200, 6204, 6227, 6236, 6237, 6250, 6262, 6297, 6299, 6307, 6317, 6320, 6327, 6328, 6329, 6331, 6348, 6353, 6354, 6365, 6367, 6368, 6373, 6374, 6390, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6437, 6440, 6449, 6463, 6465, 6469, 6503, 6507, 6513, 6521, 6532, 6537, 6545, 6550, 6555, 6562, 6572, 6587, 6593, 6629, 6635, 6664, 6669, 6674, 6681, 6693, 6703, 6713, 6718, 6723, 6726, 6736, 6771, 6777, 6789, 6792, 6803, 6830, 6835, 6858, 6862, 6871, 6885, 6889, 6893, 6896, 6909, 6914, 6921, 6929, 6942, 6953, 6959, 6984, 6987, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7193, 7197, 7204, 7208, 7210, 7211, 7225, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8438, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8496, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8583, 8584, 8585, 8588, 8590, 8592, 8595, 8597, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8616, 8618, 8619, 8622, 8625, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8696, 8700, 8701, 8706, 8708, 8709, 8711, 8713, 8717, 8722, 8724, 8725, 8728, 8729, 8730, 8733, 8736, 8737, 8741, 8742, 8745, 8747, 8750, 9084, 9085, 9086, 9087, 9088, 9090, 9091, 9102, 9103, 9104, 9105, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9154, 9155, 9156]"
      ],
      "outputs": [],
      "execution_count": 315,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[response16_idx]\n",
        "df = df[df['response_16'].notna()]\n",
        "df['response_16'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 16 specialist data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 319,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 16 specialist data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_16'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_16 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_16'].notna()]\n",
        "\n",
        "df['response_16'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018290432
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018293809
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018298120
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 131,
      "metadata": {
        "gather": {
          "logged": 1673018300629
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018304511
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018311767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 328,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018323633
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed specialist response 16 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018326969
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 138,
      "metadata": {
        "gather": {
          "logged": 1673018334406
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018336609
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018352128
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 339,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018362882
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 143,
      "metadata": {
        "gather": {
          "logged": 1673018366135
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 16 imputed specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018369939
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['Cirrhosis (Histology Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 145,
      "metadata": {
        "gather": {
          "logged": 1673018372904
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 146,
      "metadata": {
        "gather": {
          "logged": 1673018375373
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018378452
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018383467
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 149,
      "metadata": {
        "gather": {
          "logged": 1673018387177
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018396427
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 353,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - Cirrhosis (Histology Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018403311
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 17 - Advanced Fibrosis (Histology and Clinically Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 357,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_17'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_17 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_17'].notna()]\n",
        "\n",
        "df['response_17'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#response 17 specialist indexes\n",
        "response17_idx = [156, 218, 224, 230, 231, 235, 251, 256, 258, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1162, 1185, 1219, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1385, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2098, 2101, 2105, 4126, 4202, 4205, 4441, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4544, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4556, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4571, 4574, 4575, 4577, 4579, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4626, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4656, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5227, 5229, 5230, 5235, 5243, 5256, 5259, 5263, 5268, 5269, 5273, 5275, 5281, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5504, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5530, 5533, 5535, 5537, 5539, 5541, 5545, 5550, 5554, 5555, 5556, 5562, 5563, 5566, 5571, 5574, 5580, 5585, 5586, 5587, 5589, 5594, 5595, 5600, 5602, 5608, 5610, 5618, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5643, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5821, 5827, 5830, 5836, 5840, 5845, 5852, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5930, 5934, 5939, 5944, 5964, 5970, 5972, 5981, 5986, 5997, 5998, 6006, 6015, 6016, 6018, 6022, 6031, 6033, 6035, 6037, 6045, 6047, 6053, 6054, 6056, 6060, 6067, 6072, 6076, 6079, 6087, 6093, 6099, 6108, 6119, 6126, 6134, 6158, 6162, 6168, 6179, 6200, 6204, 6227, 6236, 6237, 6250, 6262, 6297, 6299, 6307, 6315, 6317, 6320, 6327, 6328, 6329, 6331, 6348, 6353, 6354, 6365, 6367, 6368, 6373, 6374, 6390, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6437, 6440, 6449, 6463, 6465, 6469, 6503, 6507, 6513, 6521, 6532, 6537, 6545, 6550, 6555, 6562, 6572, 6587, 6593, 6629, 6635, 6664, 6669, 6674, 6681, 6693, 6703, 6713, 6718, 6723, 6726, 6736, 6771, 6777, 6789, 6792, 6803, 6830, 6835, 6858, 6862, 6871, 6885, 6889, 6893, 6896, 6909, 6914, 6921, 6929, 6942, 6953, 6959, 6984, 6987, 7001, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7193, 7197, 7204, 7208, 7210, 7211, 7225, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8438, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8496, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8583, 8584, 8585, 8588, 8590, 8592, 8595, 8597, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8616, 8618, 8619, 8622, 8625, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8696, 8699, 8700, 8701, 8706, 8708, 8709, 8711, 8713, 8715, 8717, 8722, 8724, 8725, 8728, 8729, 8730, 8733, 8736, 8737, 8741, 8742, 8745, 8747, 8750, 9084, 9085, 9086, 9087, 9088, 9090, 9091, 9102, 9103, 9104, 9105, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9154, 9155, 9156]"
      ],
      "outputs": [],
      "execution_count": 359,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[response17_idx]\n",
        "df = df[df['response_17'].notna()]\n",
        "df['response_17'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 17 specialist data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 363,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 17 specialist data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_17'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_17 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_17'].notna()]\n",
        "\n",
        "df['response_17'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018410806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018419727
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 156,
      "metadata": {
        "gather": {
          "logged": 1673018422280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018425326
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018439250
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 372,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018448223
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 17 imputed specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018451942
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar chart displaying level of completeness for each feature, n = 8550\n",
        "null_values_bar = msno.bar(df,labels=True)\n",
        "null_values_bar"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018456622
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 163,
      "metadata": {
        "gather": {
          "logged": 1673018459256
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018462038
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018473522
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 383,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018482058
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 168,
      "metadata": {
        "gather": {
          "logged": 1673018486425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed specialist response 17 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Advanced Fibrosis (Histology & Clinical)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018491940
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['Advanced Fibrosis (Histology & Clinical)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 170,
      "metadata": {
        "gather": {
          "logged": 1673018494562
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 171,
      "metadata": {
        "gather": {
          "logged": 1673018496998
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018499628
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018503293
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 174,
      "metadata": {
        "gather": {
          "logged": 1673018508055
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018517988
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 397,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - Advanced Fibrosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018527579
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 18 - Cirrhosis (Histology & Clinically Confirmed)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 401,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_18'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_18 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_18'].notna()]\n",
        "\n",
        "df['response_18'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#response 18 specialist indexes\n",
        "response18_idx = [156, 218, 224, 230, 231, 235, 251, 256, 258, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1054, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1162, 1185, 1219, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1385, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2098, 2101, 2105, 4126, 4202, 4205, 4441, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4544, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4556, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4571, 4574, 4575, 4577, 4579, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4626, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4656, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5227, 5229, 5230, 5235, 5243, 5256, 5259, 5263, 5268, 5269, 5273, 5275, 5281, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5504, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5530, 5533, 5535, 5537, 5539, 5541, 5545, 5550, 5554, 5555, 5556, 5562, 5563, 5566, 5571, 5574, 5580, 5585, 5586, 5587, 5589, 5594, 5595, 5600, 5602, 5608, 5610, 5618, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5643, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5821, 5827, 5830, 5836, 5840, 5845, 5852, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5930, 5934, 5939, 5944, 5964, 5970, 5972, 5981, 5986, 5997, 5998, 6006, 6015, 6016, 6018, 6022, 6031, 6033, 6035, 6037, 6045, 6047, 6053, 6054, 6056, 6060, 6067, 6072, 6076, 6079, 6087, 6093, 6099, 6108, 6119, 6126, 6134, 6158, 6162, 6168, 6179, 6200, 6204, 6227, 6236, 6237, 6250, 6262, 6297, 6299, 6307, 6315, 6317, 6320, 6327, 6328, 6329, 6331, 6348, 6353, 6354, 6365, 6367, 6368, 6373, 6374, 6390, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6437, 6440, 6449, 6463, 6465, 6469, 6503, 6507, 6513, 6521, 6532, 6537, 6545, 6550, 6555, 6562, 6572, 6587, 6593, 6629, 6635, 6664, 6669, 6674, 6681, 6693, 6703, 6713, 6718, 6723, 6726, 6736, 6771, 6777, 6789, 6792, 6803, 6830, 6835, 6858, 6862, 6871, 6885, 6889, 6893, 6896, 6909, 6914, 6921, 6929, 6942, 6953, 6959, 6984, 6987, 7001, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7193, 7197, 7204, 7208, 7210, 7211, 7225, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8438, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8496, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8583, 8584, 8585, 8588, 8590, 8592, 8595, 8597, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8616, 8618, 8619, 8622, 8625, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8696, 8699, 8700, 8701, 8706, 8708, 8709, 8711, 8713, 8715, 8717, 8722, 8724, 8725, 8728, 8729, 8730, 8733, 8736, 8737, 8741, 8742, 8745, 8747, 8750, 9084, 9085, 9086, 9087, 9088, 9090, 9091, 9102, 9103, 9104, 9105, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9154, 9155, 9156]"
      ],
      "outputs": [],
      "execution_count": 403,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[response18_idx]\n",
        "df = df[df['response_18'].notna()]\n",
        "df['response_18'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 18 specialist data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 407,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 18 specialist data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_18'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_18 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_18'].notna()]\n",
        "\n",
        "df['response_18'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018789679
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018794374
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018799071
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 181,
      "metadata": {
        "gather": {
          "logged": 1673018802173
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018807403
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018816005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 416,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018827790
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed specialist response 18 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018833543
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 188,
      "metadata": {
        "gather": {
          "logged": 1673018845947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018850159
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018862125
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 427,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018871257
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 193,
      "metadata": {
        "gather": {
          "logged": 1673018874821
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read imputed specialist response 18 data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'Cirrhosis (Histology & Clinically Confirmed)']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018879720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['Cirrhosis (Histology & Clinically Confirmed)']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": 195,
      "metadata": {
        "gather": {
          "logged": 1673018883868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 196,
      "metadata": {
        "gather": {
          "logged": 1673018886948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018892135
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018895868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 199,
      "metadata": {
        "gather": {
          "logged": 1673018899148
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018910994
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 441,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - Cirrhosis (Histology & Clinically Confirmed)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018917658
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response 20 - At-Risk MASLD"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Only considering Baseline Event Types\n",
        "df = pd.read_csv(#read data)\n",
        "df = df[df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "df = df[df['TBL.METRICS..MET_ADM_COHORT_LITMUS'] == 'METACOHORT']"
      ],
      "outputs": [],
      "execution_count": 445,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_20'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_20 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_20'].notna()]\n",
        "\n",
        "df['response_20'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#response 20 specialist indexes\n",
        "response20_idx = [156, 218, 224, 230, 231, 251, 256, 494, 500, 508, 513, 518, 524, 529, 533, 541, 545, 551, 555, 566, 567, 705, 714, 716, 721, 722, 730, 733, 738, 745, 759, 762, 803, 814, 849, 867, 871, 905, 906, 910, 912, 948, 962, 965, 996, 1032, 1034, 1038, 1039, 1042, 1044, 1047, 1051, 1055, 1056, 1059, 1087, 1106, 1143, 1144, 1185, 1273, 1305, 1308, 1309, 1322, 1327, 1371, 1372, 1374, 1379, 1380, 1390, 1391, 1395, 1396, 1399, 2088, 2092, 2095, 2101, 2105, 4126, 4202, 4205, 4445, 4521, 4522, 4523, 4526, 4529, 4531, 4532, 4534, 4535, 4537, 4538, 4539, 4540, 4542, 4543, 4546, 4547, 4550, 4551, 4552, 4554, 4555, 4558, 4559, 4560, 4561, 4565, 4568, 4569, 4575, 4577, 4581, 4589, 4593, 4596, 4601, 4608, 4615, 4617, 4618, 4619, 4621, 4623, 4627, 4629, 4638, 4639, 4641, 4643, 4646, 4647, 4653, 4657, 4659, 4660, 4661, 4662, 4664, 4665, 4683, 4684, 4688, 4692, 4693, 4695, 4696, 5169, 5174, 5176, 5178, 5184, 5195, 5196, 5211, 5214, 5215, 5216, 5219, 5224, 5230, 5235, 5256, 5259, 5273, 5275, 5287, 5294, 5297, 5308, 5330, 5341, 5345, 5347, 5354, 5363, 5364, 5374, 5375, 5377, 5391, 5393, 5414, 5419, 5449, 5484, 5485, 5502, 5507, 5509, 5510, 5511, 5513, 5514, 5516, 5521, 5522, 5524, 5533, 5535, 5545, 5550, 5554, 5563, 5566, 5571, 5580, 5585, 5586, 5587, 5589, 5595, 5600, 5602, 5608, 5610, 5622, 5627, 5629, 5630, 5632, 5634, 5635, 5639, 5640, 5644, 5645, 5646, 5647, 5648, 5785, 5790, 5814, 5827, 5830, 5836, 5840, 5845, 5866, 5870, 5876, 5901, 5909, 5914, 5920, 5934, 5944, 5964, 5970, 5972, 5981, 5997, 5998, 6006, 6015, 6018, 6031, 6035, 6037, 6047, 6053, 6054, 6060, 6067, 6072, 6079, 6087, 6093, 6099, 6108, 6119, 6134, 6162, 6168, 6179, 6200, 6236, 6237, 6250, 6262, 6297, 6299, 6320, 6327, 6328, 6353, 6354, 6368, 6373, 6401, 6403, 6409, 6414, 6423, 6424, 6430, 6436, 6440, 6449, 6463, 6503, 6507, 6513, 6521, 6532, 6545, 6550, 6562, 6572, 6587, 6593, 6629, 6664, 6669, 6674, 6681, 6703, 6713, 6718, 6723, 6736, 6771, 6777, 6789, 6792, 6803, 6835, 6858, 6871, 6885, 6893, 6896, 6909, 6929, 6953, 6959, 6984, 6987, 7010, 7030, 7033, 7064, 7067, 7072, 7078, 7080, 7088, 7096, 7099, 7107, 7109, 7112, 7126, 7160, 7204, 7208, 7211, 7226, 7229, 7237, 7250, 7251, 8285, 8287, 8290, 8293, 8301, 8308, 8314, 8316, 8323, 8329, 8339, 8349, 8350, 8352, 8353, 8354, 8355, 8360, 8362, 8363, 8364, 8366, 8367, 8368, 8369, 8370, 8371, 8373, 8376, 8379, 8380, 8381, 8382, 8383, 8386, 8391, 8392, 8394, 8398, 8404, 8411, 8412, 8413, 8418, 8420, 8421, 8422, 8423, 8424, 8425, 8430, 8431, 8432, 8435, 8436, 8442, 8452, 8457, 8463, 8464, 8475, 8478, 8497, 8501, 8506, 8510, 8513, 8518, 8520, 8525, 8539, 8541, 8544, 8547, 8550, 8553, 8556, 8560, 8561, 8563, 8566, 8568, 8572, 8575, 8577, 8580, 8584, 8585, 8588, 8592, 8595, 8599, 8602, 8606, 8607, 8609, 8611, 8613, 8614, 8618, 8619, 8622, 8627, 8630, 8632, 8637, 8639, 8641, 8643, 8644, 8658, 8678, 8680, 8685, 8693, 8700, 8708, 8713, 8724, 8725, 8728, 8729, 8730, 8737, 8741, 8742, 8747, 9084, 9085, 9086, 9088, 9090, 9091, 9102, 9103, 9104, 9107, 9110, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9121, 9123, 9125, 9126, 9128, 9129, 9130, 9131, 9134, 9135, 9139, 9140, 9142, 9148, 9150, 9151, 9152, 9153, 9156]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.loc[response20_idx]\n",
        "df = df[df['response_20'].notna()]\n",
        "df['response_20'].isna().sum()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(#save response 20 specialist data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 451,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 20 specialist data)\n",
        "\n",
        "features_list = {\n",
        "    'std_clinical_features' :['CPH_EV_AGE_CALC',\n",
        "           'TBL.PATIENT.INFO..PI_BL_GENDER',\n",
        "           'CPH_EV_CI_BMI_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_SF_ALCO_XS',\n",
        "            'insulin_resistance',\n",
        "            'hypertensive',\n",
        "            'waist_to_hip_ratio',\n",
        "            'idf_metabolic_syndrome',\n",
        "            'eGFR',\n",
        "            'dyslipidaemia',\n",
        "            'fibroscan_stiffness_reliable',\n",
        "            'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_AST_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "            'TBL.ALL.EVENTS..AE_BR_PLT_109L',\n",
        "            'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "           'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "            'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "            'TBL.ALL.EVENTS..AE_CD_OSA'\n",
        "                             ],\n",
        "    \n",
        "    'single_markers':[\n",
        "            'LIT_NB_CK18_M30',\n",
        "            'LIT_NB_CK18_M65',\n",
        "            'LIT_NB_PRO_C3',\n",
        "            'LIT_NB_PRO_C6'],\n",
        " \n",
        "   \n",
        "    'multi_markers':[\n",
        "            'LIT_NB_ELF',\n",
        "            'FIB4',\n",
        "            'NFS',\n",
        "            'APRI',\n",
        "            'ADAPT',\n",
        "            'FIBC3',\n",
        "            'ABC3D',\n",
        "            'BARD',\n",
        "            'AST_ALT_Ratio'\n",
        "           ],\n",
        "    \n",
        "    'target':[\n",
        "        'response_20'\n",
        "    ]\n",
        "}\n",
        "features = []\n",
        "features = features + features_list['std_clinical_features']\n",
        "features = features + features_list['single_markers']\n",
        "features = features + features_list['multi_markers']\n",
        "features = features + features_list['target']\n",
        "\n",
        "#Remove all rows where response_20 = NaN\n",
        "df = df[features]\n",
        "df = df[df['response_20'].notna()]\n",
        "\n",
        "df['response_20'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018923279
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018927119
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018931441
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 206,
      "metadata": {
        "gather": {
          "logged": 1673018934552
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018939173
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018951218
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB - Specialist Variables - At-Risk MASLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018957564
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#imputed response 20 specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018961859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 213,
      "metadata": {
        "gather": {
          "logged": 1673018972041
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets  \n",
        "X = df.iloc[:,:35]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018975348
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673018982690
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train, \n",
        "    y = y_train, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 471,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE - Specialist Variables - At-Risk MASLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019002588
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost + MICE + SMOTE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "outputs": [],
      "execution_count": 218,
      "metadata": {
        "gather": {
          "logged": 1673019005700
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(#read response 20 imputed specialist data)\n",
        "df.columns = ['Age', 'Gender', 'BMI', 'Excessive Alcohol Consumption', 'Insulin Resistance', 'Hypertensive',\n",
        "              'Waist-to-Hip Ratio',\n",
        "              'Metabolic Syndrome', 'eGFR','Dyslipidaemia', 'Fibroscan Stiffness', 'ALT', 'AST', 'GGT', 'Ferritin', 'Platelets', 'Creatinine',\n",
        "              'Serum Triglycerides', 'Albumin', 'Bilirubin', 'IgA', 'Obstructive Sleep Apnoea',\n",
        "              'CK18-M30','CK18-M65','Pro-C3','Pro-C6','ELF','FIB4',\n",
        "              'NFS', 'APRI','ADAPT','FIBC3','ABC3D','BARD','AST-ALT Ratio',\n",
        "              'response_20']\n",
        "df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019009542
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test sets\n",
        "X = df.iloc[:,:35]\n",
        "y = df['response_20']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019013075
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": 221,
      "metadata": {
        "gather": {
          "logged": 1673019016539
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019019454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019022390
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify XGBoost Classifiers static parameters\n",
        "XGBCL_STATIC_PARAMS = {\n",
        "    'base_score': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'colsample_bylevel': 1.0,\n",
        "    'max_delta_step': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'missing': None,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'binary:logistic',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 1.0,\n",
        "    'tree_method': 'auto'\n",
        "}\n",
        "\n",
        "#Specify number of k-fold cross validation\n",
        "KFOLD_STATIC_PARAMS = {\n",
        "    'n_splits': 5,  # At least 2\n",
        "    'shuffle': True, \n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "#Specify grid search static parameters\n",
        "SEARCH_GRID_STATIC_PARAMS = {\n",
        "    'n_jobs': -1, \n",
        "    'scoring': 'accuracy',  # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "#Grid search XGBoost parameters with following values / ranges\n",
        "SEARCH_GRID_PARAMS = { \n",
        "    'colsample_bytree':[.75, .8, 1],\n",
        "    'learning_rate':[0.001, 0.01, 0.1],\n",
        "    #'gamma': [0.0, 1.0],\n",
        "    'max_depth':[1,2,5,8,12],\n",
        "    'n_estimators': list(range(50, 300, 50)),\n",
        "    #'num_parallel_tree': [1, 2, 4, 8],\n",
        "    #'reg_alpha': [0.0, 0.5, 1.0],\n",
        "    #'reg_lambda': [0.0, 0.5, 1.0],\n",
        "    #'subsample':[.75,1],\n",
        "}\n",
        "\n",
        "#Allocate the static XGBoost parameters to our XGBoost classifier\n",
        "\n",
        "xgbcl = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method']\n",
        ")\n",
        "\n",
        "#Specify k-fold cross-validation\n",
        "kfold = StratifiedKFold(\n",
        "    n_splits = KFOLD_STATIC_PARAMS['n_splits'], \n",
        "    shuffle = KFOLD_STATIC_PARAMS['shuffle'], \n",
        "    random_state = KFOLD_STATIC_PARAMS['random_state']\n",
        ")\n",
        "\n",
        "#Define grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = xgbcl,\n",
        "    param_grid = SEARCH_GRID_PARAMS, \n",
        "    cv = kfold,\n",
        "    n_jobs = SEARCH_GRID_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = SEARCH_GRID_STATIC_PARAMS['scoring'],\n",
        "    verbose = SEARCH_GRID_STATIC_PARAMS['verbose']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 224,
      "metadata": {
        "gather": {
          "logged": 1673019025516
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Begin grid search for best parameters in XGBoost classifier for X_train data fitted onto y_train data\n",
        "start_time = time.time()\n",
        "grid_result = grid_search.fit(X_train_res, y_train_res)\n",
        "grid_search_time = time.time() - start_time\n",
        "print(f'Training performed in {grid_search_time/60} minutes')\n",
        "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}','\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print XGBoost model that gave best accuracy score from grid search\n",
        "model = xgb.XGBClassifier(\n",
        "    base_score = XGBCL_STATIC_PARAMS['base_score'],\n",
        "    booster = XGBCL_STATIC_PARAMS['booster'],\n",
        "    colsample_bylevel = XGBCL_STATIC_PARAMS['colsample_bylevel'],\n",
        "    max_delta_step = XGBCL_STATIC_PARAMS['max_delta_step'],\n",
        "    min_child_weight = XGBCL_STATIC_PARAMS['min_child_weight'],\n",
        "    missing = XGBCL_STATIC_PARAMS['missing'],\n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    objective = XGBCL_STATIC_PARAMS['objective'],\n",
        "    random_state = XGBCL_STATIC_PARAMS['random_state'],\n",
        "    scale_pos_weight = XGBCL_STATIC_PARAMS['scale_pos_weight'],\n",
        "    tree_method = XGBCL_STATIC_PARAMS['tree_method'],\n",
        "    \n",
        "    colsample_bytree = grid_result.best_params_['colsample_bytree'], \n",
        "    learning_rate = grid_result.best_params_['learning_rate'], \n",
        "    #gamma = grid_result.best_params_['gamma'],\n",
        "    max_depth = grid_result.best_params_['max_depth'], \n",
        "    n_estimators = grid_result.best_params_['n_estimators'],\n",
        "    #num_parallel_tree = grid_result.best_params_['num_parallel_tree'],\n",
        "    #reg_alpha = grid_result.best_params_['reg_alpha'],\n",
        "    #reg_lambda = grid_result.best_params_['reg_lambda'],\n",
        "    #subsample = grid_result.best_params_['subsample'],\n",
        "\n",
        ")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model onto X_train and y_train data\n",
        "model.fit(X_train_res,y_train_res)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019040049
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#refit the model on k-folds to get stable avg error metrics\n",
        "scores = cross_validate(\n",
        "    estimator = model, \n",
        "    X = X_train_res, \n",
        "    y = y_train_res, \n",
        "    cv = kfold, \n",
        "    n_jobs = XGBCL_STATIC_PARAMS['n_jobs'],\n",
        "    scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 485,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Print metrics to evaluate model. \n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "sens = tp / (tp + fn)\n",
        "\n",
        "print('AUC: ',       scores['test_roc_auc'].mean())\n",
        "print('Accuracy: ',  scores['test_accuracy'].mean())\n",
        "print('sensitivity:', sens)\n",
        "print('specificity:', spec)\n",
        "print('F1: ',        scores['test_f1'].mean())\n",
        "print('Test set score: {:.4f}'.format(model.score(X_test, y_test)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Add SHAP values\n",
        "\n",
        "explainer = shap.TreeExplainer(\n",
        "    model, \n",
        "    model_output='probability', \n",
        "    feature_dependence='interventional', \n",
        "    data=X_train_res\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(X_train_res)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "shap_values\n",
        "\n",
        "#Bar chart represents the mean SHAP averages, i.e. the average impact on the model's output magnitude.\n",
        "shap.summary_plot(shap_values, X_train_res, plot_type=\"bar\",show=False)\n",
        "plt.title(\"XGB + MICE + SMOTE - Specialist Variables - At-Risk MASLD\")\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673019054257
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}